####1. zookeeper 核心
    文件系统 + 通知机制
####2. zookeeper ZAB 协议
    zookeeper atomic broadcast 原子广播
    原子性: 写消息到达一台机器则会到达所有消息
    顺序性: 消息a 在 消息b 之前处理，那么在所有机器上都是一样的

####3. watcher 机制
    1. watcher 只会被消费一次，客户端如果需要持续监听需要反复注册，这个动作由客户端控制，减小服务端通知的压力。
    2. 轻量级设计，watcher 回调只会告知：节点位置、事件类型、节点状态
    3. 串行式设计，客户端注册的多个 watcher 如果同时触发会串行通知，由此客户端注意处理 watcher 时不要阻断整个串行回调。
####4. 客户端简单使用
    zkclient && curator 提供比自带 client 更好的功能
    1. watcher 反复注册
    2. 序列化
    3. 超时重连

####5. 安全认证
    ACL 机制，访问控制方式，有基于密码，ip，授权等等
####6. 实现分布式锁
####7. 为什么是单数集群数量
    主要是可用性考虑。
    zk 集群要对外保证可用需要节点正常数量大于一半，那么 3 台 和 4 台能容忍不可用的台数就都是 1 台了，节约资源考虑奇数台较好。
####8. zookeeper 数据模型
####9. zookeeper 投票过程
    1. 当进入 zookeeper 的崩溃恢复模式的时候，开始 FastLeaderElection 算法进行 leader 选举
    2. 每个机器投票都包含两个信息，sid(server id), zxid(事务数据 id,越大说明数据越新），优先推举 zxid 较大的机器
    3. 当有三台机器进行选举，分别是：A(4, 8) 、B(5, 8)、C(6, 7)
    4. 第一轮：各自投自己，并收到别的机器的投票：
        A:(4,8),(5,8),(6,7)-->(5,8)
        B:(4,8),(5,8),(6,7)-->(5,8)
        C:(4,8),(5,8),(6,7)-->(5,8)
    5. 第二轮：重新统计选票，B 机器获得大于一半机器的投票，当选 leader。
    
####10. zookeeper 脑裂
    zookeeper 从众机制避免了脑裂可能，之前假死的 master 恢复通信后由于节点总数发生变化，会重新发起选举过程。
    
####11. zookeeper 两阶段提交
    master 向 slave 写数据需要在写每一个 slave 的时候进行预提交，等待都写成功才真正发起提交。